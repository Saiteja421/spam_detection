{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saiteja421/spam_detection/blob/main/spam_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Spam Detection with Multinomial Naive Bayes Algorithm**\n",
        "---\n",
        "# Description\n",
        "\n",
        "> Naive Bayes is a simple and effective method for predicting the class of a data point based on the values of features that describe that data point. It is based on the idea of using Bayes' theorem, a rule in probability theory, to estimate the probability that an event will occur given the prior knowledge of certain conditions.\n",
        "\n",
        "> In the context of classification, Naive Bayes can be used to predict the class of a data point based on the values of a set of features that describe that data point. For example, in a spam filtering application, the features might include the presence of certain words in an email, and the class would be \"spam\" or \"not spam\". The Naive Bayes classifier would use the values of these features to estimate the probability that an email is spam, and make a prediction accordingly.\n",
        "\n",
        ">In this project we'll build a model that classifies messages as spam or non-spam."
      ],
      "metadata": {
        "id": "UeMvRonj0vDs"
      },
      "id": "UeMvRonj0vDs"
    },
    {
      "cell_type": "markdown",
      "id": "a814eae4",
      "metadata": {
        "id": "a814eae4"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Table of contents\n",
        "\n",
        "* **Importing Libraries**\n",
        "* **Reading Data**\n",
        "* **Creating Training and Testing Set**\n",
        "* **Data Cleaning**\n",
        "* **Calculating Probabilities**\n",
        "* **Building the Classifier**\n",
        "* **Testing**\n",
        "* **Conclusions**\n",
        "\n",
        "## Importing Libraries "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_NbFEuuDQ9F_"
      },
      "id": "_NbFEuuDQ9F_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c5e07c",
      "metadata": {
        "id": "31c5e07c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f808d61",
      "metadata": {
        "id": "1f808d61"
      },
      "source": [
        "## Reading Data\n",
        "\n",
        "This dataset is taken from [Kaggle.com](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)\n",
        "\n",
        "Import the Google Drive module in Google Colab and mount it to download the dataset for training and testing the model.\n",
        "\n",
        "I have downloaded the dataset by providing the path to my Google Drive where I had already saved the dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ec5d59d",
      "metadata": {
        "id": "6ec5d59d"
      },
      "outputs": [],
      "source": [
        "messages = pd.read_csv('/content/drive/MyDrive/DWDM Dataset/SMSSpamCollection', sep = \"\\t\", header = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed136d2c",
      "metadata": {
        "id": "ed136d2c"
      },
      "outputs": [],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75e24d6",
      "metadata": {
        "id": "c75e24d6"
      },
      "outputs": [],
      "source": [
        "messages.columns = [\"Label\", \"Message\"] #Labeling the columns as Label and Message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0335e59d",
      "metadata": {
        "id": "0335e59d"
      },
      "outputs": [],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cda67ea",
      "metadata": {
        "id": "0cda67ea"
      },
      "outputs": [],
      "source": [
        "messages[\"Label\"].value_counts().plot.bar(rot = 30)\n",
        "plt.xlabel(\"Message Label\")\n",
        "plt.ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a6c559",
      "metadata": {
        "id": "37a6c559"
      },
      "outputs": [],
      "source": [
        "messages[\"Label\"].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96201888",
      "metadata": {
        "id": "96201888"
      },
      "source": [
        "\n",
        "\n",
        "## Creating Training and Testing Set\n",
        "\n",
        "We will split the original dataset randomly\n",
        "\n",
        "80% of the data --> will be used for training, \n",
        "\n",
        "20% remaining --> will be used for testing. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c4d3b7",
      "metadata": {
        "id": "44c4d3b7"
      },
      "outputs": [],
      "source": [
        "# random data\n",
        "random_data = messages.sample(frac = 1, random_state = 1)\n",
        "\n",
        "# lengths of the training and testing data, that will be used as future indexes\n",
        "len_train = round(len(random_data) * .8)\n",
        "len_test = len(random_data) - len_train\n",
        "\n",
        "print(len_train, len_test, len_train + len_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c55ebe",
      "metadata": {
        "id": "c2c55ebe"
      },
      "outputs": [],
      "source": [
        "random_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11ef15e",
      "metadata": {
        "id": "f11ef15e"
      },
      "outputs": [],
      "source": [
        "# creating the sets using slicing\n",
        "training = random_data[:len_train].reset_index(drop = True)\n",
        "testing = random_data[-len_test:].reset_index(drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c86947",
      "metadata": {
        "id": "b2c86947"
      },
      "outputs": [],
      "source": [
        "print(training.shape, testing.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee2722d",
      "metadata": {
        "id": "3ee2722d"
      },
      "outputs": [],
      "source": [
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03552531",
      "metadata": {
        "id": "03552531"
      },
      "outputs": [],
      "source": [
        "testing.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa4b4ebe",
      "metadata": {
        "id": "aa4b4ebe"
      },
      "source": [
        "We now check that the proportions of spam and non-spam messages are kept similar to those of the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb09eeb",
      "metadata": {
        "id": "2eb09eeb"
      },
      "outputs": [],
      "source": [
        "training[\"Label\"].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f89fea1c",
      "metadata": {
        "id": "f89fea1c"
      },
      "outputs": [],
      "source": [
        "testing[\"Label\"].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fa3a41",
      "metadata": {
        "id": "28fa3a41"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "\n",
        "So we will need to clean the data in order to obtain the pieces of information we need.\n",
        "\n",
        "Recall that the model treats each word indepedently, so we don't care about the entire message. We only care about the frequencies of each word in a message.\n",
        "\n",
        "We will do some assumptions\n",
        "\n",
        "All words will be lowercased and punctuation will be neglegted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d353014",
      "metadata": {
        "id": "9d353014"
      },
      "outputs": [],
      "source": [
        "# \"\\W\" is a regex command that matches character that are not a-z, A-Z, 0-9 and _\n",
        "training[\"Message\"] = training[\"Message\"].str.replace(\"\\W\", \" \", regex  = True).str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66197e24",
      "metadata": {
        "id": "66197e24"
      },
      "outputs": [],
      "source": [
        "training.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "804347e7",
      "metadata": {
        "id": "804347e7"
      },
      "outputs": [],
      "source": [
        "# creating the vocabulary\n",
        "vocabulary = []\n",
        "training[\"Message\"] = training[\"Message\"].str.split()\n",
        "for message in training[\"Message\"]:\n",
        "    for word in message:\n",
        "        if word not in vocabulary:\n",
        "            vocabulary.append(word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b1d828",
      "metadata": {
        "id": "81b1d828"
      },
      "outputs": [],
      "source": [
        "# checking that there are no duplicates in the vocabulary\n",
        "print(len(vocabulary) == len(set(vocabulary)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcfd7c6",
      "metadata": {
        "id": "2bcfd7c6"
      },
      "outputs": [],
      "source": [
        "vocabulary[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a1a771",
      "metadata": {
        "scrolled": true,
        "id": "03a1a771"
      },
      "outputs": [],
      "source": [
        "d = len(vocabulary)\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c34495",
      "metadata": {
        "id": "88c34495"
      },
      "source": [
        "There are 7783 unique words in the messages. Now we will split the Message column into multiple columns for each word in the vocabulary, setting the values as the frequencies of the words in each message. We will do so creating a dictionary first and then converting it to a dataframe that we will concatenate to the original training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c44e9ed",
      "metadata": {
        "id": "5c44e9ed"
      },
      "outputs": [],
      "source": [
        "# creating the dictionary that will be converted to a dataframe\n",
        "word_freq_per_message = {word:[0]*len(training[\"Message\"]) for word in vocabulary}\n",
        "\n",
        "# adding the frequencies to word_freq_per_message\n",
        "for i, message in enumerate(training[\"Message\"]):\n",
        "    for word in message: # recall that 'message' is a list of words, saved as strings\n",
        "        word_freq_per_message[word][i] += 1\n",
        "        \n",
        "words_freq_per_message = pd.DataFrame(word_freq_per_message)\n",
        "words_freq_per_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ccd546a",
      "metadata": {
        "id": "1ccd546a"
      },
      "outputs": [],
      "source": [
        "training_final = pd.concat([training, words_freq_per_message], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7216fa48",
      "metadata": {
        "id": "7216fa48"
      },
      "outputs": [],
      "source": [
        "training_final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b39db4",
      "metadata": {
        "id": "c2b39db4"
      },
      "source": [
        "## Calculating Probabilities\n",
        "\n",
        "Now that we have a dataset that is useful for our scenario, we can proceed doing our calculations. Since the formulas are a bit long, I will repaste them here:\n",
        "$$P(spam|word_1, word_2,\\dots , word_n) \\propto P(spam)\\cdot \\prod_{i = 1}^{n}P(word_i|spam)$$\n",
        "$$P(non\\ spam|word_1,word_2,\\dots , word_n) \\propto P(non\\ spam)\\cdot \\prod_{i = 1}^{n}P(word_i|non\\ spam)$$\n",
        "$$P(word_i|spam) = \\frac{X_i + \\alpha}{N + \\alpha \\cdot d}$$ where $X_i$ is represents the frequency of $word_i$ in a spam message, $\\alpha$ is the smoothing parameter (we'll set it to 1), $N$ is the number of words in the spam set, $d$ is the number of words in our vocabulary. The same is applied when we condition on \"non-spam\" messages.\n",
        "\n",
        "Let's start with $P(spam)$ and $P(non\\ spam)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974e9dcb",
      "metadata": {
        "id": "974e9dcb"
      },
      "outputs": [],
      "source": [
        "prob_spam = len(training_final[training_final[\"Label\"] == \"spam\"]) / len(training_final[\"Label\"])\n",
        "prob_nonspam = 1 - prob_spam\n",
        "print(prob_spam, prob_nonspam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37fb8731",
      "metadata": {
        "id": "37fb8731"
      },
      "source": [
        "\n",
        "\n",
        "Now, Let's go on calculating $P(word_i|C_k)$ where $C_k$ is either $spam$ or $non\\ spam$. Since there are 7783 words in the vocabulary, and we need to calculate the probabilities in both cases, we need to so 15566 computations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1951287a",
      "metadata": {
        "id": "1951287a"
      },
      "outputs": [],
      "source": [
        "# calculating P(word_i|C_k)\n",
        "spam_messages = training_final[training_final[\"Label\"] == \"spam\"]\n",
        "nonspam_messages = training_final[training_final[\"Label\"] == \"ham\"]\n",
        "\n",
        "alpha = 1\n",
        "n_spam = spam_messages[\"Message\"].apply(len).sum()\n",
        "n_nonspam = nonspam_messages[\"Message\"].apply(len).sum()\n",
        "# we defined \"d\" previously in our code\n",
        "print(alpha, n_spam, n_nonspam, d)\n",
        "\n",
        "prob_word_given_spam = {}\n",
        "prob_word_given_nonspam = {}\n",
        "\n",
        "for word in vocabulary:\n",
        "    prob_word_given_spam[word] = (spam_messages[word].sum() + alpha) / (n_spam + alpha * d)\n",
        "    prob_word_given_nonspam[word] = (nonspam_messages[word].sum() + alpha) / (n_nonspam + alpha * d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c585d664",
      "metadata": {
        "id": "c585d664"
      },
      "outputs": [],
      "source": [
        "print(dict(list(prob_word_given_spam.items())[:3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e89a98",
      "metadata": {
        "id": "f0e89a98"
      },
      "outputs": [],
      "source": [
        "print(dict(list(prob_word_given_nonspam.items())[:3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d87063db",
      "metadata": {
        "id": "d87063db"
      },
      "source": [
        "**NOTE**: doing so many calculations before the classification is what makes Naive Bayes very fast! If we did not do so, we would need to do all these calculations for every new message! Now, instead, most of them are already done. Hence Naive Bayes is\n",
        "more accurate than many other methods of classification.\n",
        "\n",
        "## Building the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7952d2ff",
      "metadata": {
        "id": "7952d2ff"
      },
      "outputs": [],
      "source": [
        "def classify(message):\n",
        "    if not isinstance(message, str):\n",
        "        raise Exception(\"Argument must be a string\")\n",
        "    \n",
        "    message = re.sub(\"\\W\", \" \", message)\n",
        "    message = message.lower().split()\n",
        "    \n",
        "    prob_spam_given_message = prob_spam\n",
        "    prob_nonspam_given_message = prob_nonspam\n",
        "    for word in message:\n",
        "        if word in prob_word_given_spam:\n",
        "            prob_spam_given_message *= prob_word_given_spam[word]\n",
        "        if word in prob_word_given_nonspam:\n",
        "            prob_nonspam_given_message *= prob_word_given_nonspam[word]\n",
        "    # we added these if clauses to avoid issues when a word of a message is not present in our list (see README for more)\n",
        "    \n",
        "    if prob_spam_given_message > prob_nonspam_given_message:\n",
        "        res = \"spam\"\n",
        "    elif prob_spam_given_message < prob_nonspam_given_message:\n",
        "        res = \"ham\"\n",
        "    else: # if there is equality. It is unlikely to occur, since we're comparing float numbers\n",
        "        res = \"Classification failed\"\n",
        "        \n",
        "    return prob_spam_given_message, prob_nonspam_given_message, res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e2ce83",
      "metadata": {
        "id": "d0e2ce83"
      },
      "outputs": [],
      "source": [
        "# checking boundary case\n",
        "classify('3')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4ff47b9",
      "metadata": {
        "id": "c4ff47b9"
      },
      "source": [
        "Looking at the documentation, we have some examples of spam and non-spam messages. Let's test them:\n",
        "\n",
        "* ham: What you doing?how are you?\n",
        "* ham: Ok lar... Joking wif u oni...\n",
        "* ham: dun say so early hor... U c already then say...\n",
        "* ham: MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*\n",
        "* ham: Siva is in hostel aha:-.\n",
        "* ham: Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor.\n",
        "* spam: FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop\n",
        "* spam: Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B\n",
        "* spam: URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f0250b",
      "metadata": {
        "id": "f4f0250b"
      },
      "outputs": [],
      "source": [
        "classify(\"What you doing?how are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d65481",
      "metadata": {
        "id": "69d65481"
      },
      "outputs": [],
      "source": [
        "classify(\"Ok lar... Joking wif u oni...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e109d68f",
      "metadata": {
        "id": "e109d68f"
      },
      "outputs": [],
      "source": [
        "classify(\"dun say so early hor... U c already then say...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a03f574",
      "metadata": {
        "id": "7a03f574"
      },
      "outputs": [],
      "source": [
        "classify(\"MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0bc70eb",
      "metadata": {
        "id": "b0bc70eb"
      },
      "outputs": [],
      "source": [
        "classify(\"Siva is in hostel aha:-.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10f911e",
      "metadata": {
        "id": "f10f911e"
      },
      "outputs": [],
      "source": [
        "classify(\"Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2fb127",
      "metadata": {
        "id": "cf2fb127"
      },
      "outputs": [],
      "source": [
        "classify(\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d54894",
      "metadata": {
        "id": "47d54894"
      },
      "outputs": [],
      "source": [
        "classify(\"Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07e25f4",
      "metadata": {
        "id": "b07e25f4"
      },
      "outputs": [],
      "source": [
        "classify(\"URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec981291",
      "metadata": {
        "id": "ec981291"
      },
      "source": [
        "All classifications are correct!\n",
        "\n",
        "\n",
        "## Testing\n",
        "\n",
        "We will now use the classifier on our testing set to test and check the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ac94bf",
      "metadata": {
        "id": "16ac94bf"
      },
      "outputs": [],
      "source": [
        "testing.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6698df1f",
      "metadata": {
        "id": "6698df1f"
      },
      "source": [
        "Let's add another column classification that indicates the classification made by the classify function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb74be7",
      "metadata": {
        "id": "3eb74be7"
      },
      "outputs": [],
      "source": [
        "testing[\"classification\"] = testing[\"Message\"].apply(lambda message: classify(message)[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06848be4",
      "metadata": {
        "id": "06848be4"
      },
      "outputs": [],
      "source": [
        "testing.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da6f0acd",
      "metadata": {
        "id": "da6f0acd"
      },
      "source": [
        "To calculate the model accuracy, we will check the proportions of rows in which classification == Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b9d6f65",
      "metadata": {
        "id": "1b9d6f65"
      },
      "outputs": [],
      "source": [
        "correct_class_len = 0\n",
        "total_messages = testing.shape[0] #1114\n",
        "\n",
        "for row in testing.iterrows():\n",
        "    if row[1][\"Label\"] == row[1][\"classification\"]: #we use row[1] because iterrows() returns (index,row)\n",
        "        correct_class_len += 1\n",
        "\n",
        "accuracy = correct_class_len / total_messages\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f8a2e4",
      "metadata": {
        "id": "c0f8a2e4"
      },
      "source": [
        "We achieved an accuracy of 98.7%, which is amazing!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7acc253b",
      "metadata": {
        "id": "7acc253b"
      },
      "source": [
        "\n",
        "## Conclusions\n",
        "\n",
        "\n",
        ">We have built a model that predicted whether a message was spam or not with 98.7% accuracy. The wrong classifications would require further time-consuming investigation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Future Optimisations\n",
        "\n",
        "* Make the model more complex making it case sensitive\n",
        "* Understand what caused misclassifications in the current model to understand if accuracy can be improved.\n",
        "* It would be interesting to apply a Logistic Regression (LR) and see how it performs differently. Indeed, when the classification is binary, Naive Bayes (NB) gets very close to LR. The intuitive difference is that LR directly estimates $P(C_k|\\textbf{X})$, while NB estimates values for $P(C_k)$ and $P(\\textbf{X}|C_k)$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All Cells ececuted...\")\n",
        "print(\"SUCCESSS\")"
      ],
      "metadata": {
        "id": "sKwaWBSvIIKW"
      },
      "id": "sKwaWBSvIIKW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "dde5da77d57e2d32aeafdd4b57e534404740344324fdbcc2311bc5433eb333a8"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}